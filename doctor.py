#!/usr/bin/env python
# coding: utf-8

# In[15]:


import json
import random
import nltk
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
import joblib
import streamlit as st
try:
    path = r"C:\Users\SEYED\Desktop\AI\project\Ø¨Ø§Øª Ù†ÙˆØ¨Øª Ø¯Ù‡ÛŒ\output.json"
    with open (path , "r" , encoding="utf-8") as f:
        data_set = json.load(f)
    vectorizer = joblib.load(r"C:\Users\SEYED\tfidf_vectorizer_pkl")
    model = joblib.load(r"C:\Users\SEYED\chatbot_model.pkl")
except FileNotFoundError:
    st.error("ÙØ§ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ ÛŒØ§ Ù…Ø¯Ù„ Ù‡Ø§ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯Ù†Ø¯.")
    st.stop()
#Ù†ÛŒØª
def predict_intent(text):
    text_vectorized = vectorizer.transform([text])
    intent = model.predict(text_vectorized)[0]
    probabilities = model.predict_proba(text_vectorized)
    confidence = max(probabilities[0])
    return intent , confidence
#Ø¬ÙˆØ§Ø¨
def get_respons(intent):
    for intent_obj in data_set["intents"]:
        if intent_obj["tag"]==intent:
            responses = intent_obj["respons"]
            return random.choice(responses)
    return "Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù†Ù…ÛŒØªÙˆÙ†Ù… Ù¾Ø§Ø³Ø® Ø¨Ø¯Ù…"
        
#Ú¯ÙØªÚ¯Ùˆ
st.title("Ú†Øª Ù†ÙˆØ¨Øª Ø¯Ù‡ÛŒğŸ¤–")
st.markdown(""" Ø³Ù„Ø§Ù… Ù…Ù† ÛŒÙ‡ Ø¯Ø³ØªÛŒØ§Ø±Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø±Ø§ÛŒ Ù†ÙˆØ¨Øª Ø¯Ù‡ÛŒ Ù‡Ø³ØªÙ… ğŸ˜Š. Ú†Ù‡ Ø¬ÙˆØ±ÛŒ Ù…ÛŒÙ†ÙˆÙ†Ù… Ú©Ù…Ú©Øª Ú©Ù†Ù…ØŸ Ù…ÛŒØªÙˆÙ†ÛŒ Ø§Ø²Ù… Ø¯Ø±Ø¨Ø§Ø±Ù‡
Ù†ÙˆØ¨Øª Ú¯ÛŒØ±ÛŒØŒ ØªØºÛŒÛŒØ± Ù†ÙˆØ¨ØªØŒ Ú©Ù†Ø³Ù„ÛŒ ÙˆÙ‚ØªØŒ Ø¢Ø¯Ø±Ø³ ØŒ Ø²Ù…Ø§Ù† Ù‡Ø§ÛŒ Ø­Ø¶ÙˆØ± Ø¯Ú©ØªØ± Ø¨Ù¾Ø±Ø³ÛŒ""")    
#Ø­Ø§ÙØ¸Ù‡ Ú¯ÙØªÚ¯Ùˆ
if "messages" not in st.session_state:
    st.session_state.messages =[]
#Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ù‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
#Ú¯Ø±ÙØªÙ† Ù¾ÛŒØ§Ù… Ø§Ø² Ú©Ø§Ø±Ø¨Ø± Ùˆ Ú†Ø§Ù¾
if prompt:=st.chat_input("Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯ :"):
    st.session_state.messages.append({"role":"user" , "content":prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Ù¾ÛŒØ´ÛŒÙ†ÛŒ Ù¾Ø±Ø§Ù…Ù¾Øª
    intent , confidence = predict_intent(prompt)
    if confidence<0.5:
        intent="Defult"
    response = get_respons(intent)
    #Ú†Ø§Ù¾ Ø¬ÙˆØ§Ø¨
    with st.chat_message("assistant"):
        st.markdown(response)
    st.session_state.messages.append({"role":"assistant" , "content":response})

